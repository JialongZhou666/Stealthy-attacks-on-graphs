# Towards stealthy attacks on graphs

## Paper collection on attacks


| Year | Paper/Venue | Name | Target Model | Purterbation Type | Evasion or Poisoning | Target or NonTarget | Attacker Knowlege | Datasets | Task |
| ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ |
| 2019 | XXX/XXX | Metattack | GCN |e.g., add/delete edges, node injection|XXX| XXX| XXX| XXX| node classification|
| 2022 | Unsupervised Graph Poisoning Attack via Contrastive Loss Back-propagation/WWW 2022 | CLGA | GCN | add/delete edges, gradient ascent | Cora,CiteSeer, PolBlog | node classification, link prediction | 
| 2022 | Neighboring Backdoor Attacks on GraphConvolutional Network/Arxiv | GB-FGSM,GB-IG,GB-PGD,LGCB | 2-layer GCN | backdoor attack | BlogCatalog,Flickr,Cora,Pubmed | node classification |
| 2022 | Interpretable and Effective Reinforcement Learning for Attacking against Graph-based Rumor Detection/CORR2022 |  AdRumor-RL  | RGCN | add edges| Weibo,Twitter | rumor detection |
| 2021 | Task and Model Agnostic Adversarial Attack on Graph Neural Networks/Arxiv | GRAND | GNN | neighborhood distortion | Cora,CiteSeer | node classification,link prediction,pairwise  node-classification |
| 2021 | Model Stealing Attacks Against Inductive Graph Neural Networks/IEEE S&P 2022 | Model Stealing Attack I/II | inductive GNNs: GIN, GAT, SAGE | model stealing | DBLP,Pubmed,Citeseer Full,Coauthor Physics,ACM,Amazon Co-purchase Network for Photos | node classification, model stealing |
| 2021 | How Members of Covert Networks Conceal the Identities of Their Leaders/ACM TIST 2021 | Captain Network |
| 2021 | Adapting Membership Inference Attacks to GNN for Graph Classification: Approaches and Implications/ICDM 2021 | MIA | GNNs(gateGCN,GCN,GIN,GAT,GraphSAGE,DeepGCN,MLP(baseline)) | Training-based/Threshold-based Attacks | Poisoning | Untargeted | Black-box | PRO-TEIN_full,DD,ENZYMES,OGBG-PPA,CIFAR10,MNIST,NCI | Graph Classification |
| 2021 | Graph Structural Attack by Spectral Distance/Arxiv | Spectral Attack on Graphs | GCN | Maximize spectral distance | Both | Targeted | White-box | Cora,Citeseer | Node Classification |
| 2021 | Structural Attack against Graph Based Android Malware Detection/CCS 2021 | HRAT | Graph Based Android Malware Detector | Insert Nodes,Delete nodes,Add Edges,Rewire | Poisoning | Targeted | White-box | Apps from AndroZoo | Malware Detection |
｜ 2021 | Adversarial Attacks on Knowledge Graph Embeddings via Instance Attribution Methods/EMNLP | Instance Attribution Methods | Knowledge Graph Embedding Models(DistMult,ComplEx,ConvE,TransE) | Adversarial Deletions and Additions | Poisoning | Targeted | White-box | WN18RR,FB15k-237 | Knowledge Graph Embeddings,Link Prediction |
| 2021 | Adversarial Attack against Cross-lingual Knowledge Graph Alignment/ EMNLP | EAA | representative cross-lingual entity alignment models: ATTrGNN, RNM, REA | add/delete edges | evasion(?) | target | white-box | DBP15KZH−EN, DBP15KJA−EN, DBP15KFR−EN | Knowledge Graph Alignment |
| 2021 | Graph Robustness Benchmark: Benchmarking the Adversarial Robustness of Graph Machine Learning/ NeurIPS |  |  |  |  |  |  |  | Node Classification |
| 2021 | Adversarial Attacks on Graph Classification via Bayesian Optimisation/ NeurIPS | GRABNEL | GCN (SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS) ; GIN (how powerful are graph neural networks) | add/delete edges; modify weights θ or gradient | Evasion | Both | black-box | TU datasets: IMDB-M, PROTEINS, COLLAB, REDDIT-MULTI-5K | Graph Classification |
| 2021 | Robustness of Graph Neural Networks at Scale/ NerIPS | GR-BCD; PR-BCD | Soft Median GDC (proposed in paper); Soft Median PPRGo (proposed in paper); Vanilla GCN; Vanilla GDC; Vanilla PPRGo; Soft Medoid GDC; SVD GCN; Jaccard GCN; RGCN| add/delete edges | Both | Both<br>   (local-targeted; global-untargeted) | white-box | Cora ML; Citeseer; PubMed; arXiv; Products; Papers 100M | Node Classification |
| 2021 | Large-Scale Adversarial Attacks on Graph Neural Networks via Graph Coarsening/ ICLR | GRAPH STRUCTURE POISONING VIA META-GRADIENTS;<br>GRAPH STRUCTURE POISONING VIA GRAPH COARSENING | GCN (Kipf & Welling, 2017)  | add/delete edges | Poisoning | untargeted | gray-box |  Cora; Citeseer; Polblogs; Pubmed; Amazon; CS; Physics; Arxiv | Node Classification |
| 2021 | Mind Your Solver! On Adversarial Attack and Defense for Combinatorial Optimization/ICLR 2022 OpenReview | ROCO, an adversarial framework that consists of both attack and defense models | Combinatorial Optimization Solvers |  add, delete edges |  Task1: TPC-H dataset, remove existing edges; task2: ATSP dataset, choose an edge and half its value; task3: add non-existing black edges that connect rules to black events, simulated data | Combinatorial optimization | black-box attack and defense(explicit mention white-box for further research) | targeted ( Reinforcement based) and non-targeted (Heuristic algorithm) | evasion (PPO: For training, actions are sampled w.r.t. their probabilities. For testing, beam search is adopted to find the optimal solution) | task1(DIRECTED ACYCLIC GRAPH SCHEDULING): normal/attack/defense, finish time; task2(ASYMMETRIC TRAVELING SALESMAN PROBLEM): Random, OG-Search, SA, RL, metric is the mean ratio on all test instances computed by the solved tour length w.r.t. baselines.; task3: Random, OG-Search, SA, RL, metrics is The ratio here is the mean of ratios on all test instances computed by the solved FC monetary value w.r.t. baselines. | see baseline  
| 2021 | Bandits for Black-box Attacks to Graph Neural Networks with Structure Perturbation/ICLR 2022 OpenReview | Bandit-based black-box attacks | GCN, SGC for node classification; GIN for graph classification | add, delete edges |  Cora, Citeseer, and Pubmed for node classification;  MNIST and CIFAR10 for graph classification | node classification/graph classification | black-box attack (only know prediction and neighbors) | target | evasion | RL-based attack (Dai et al.,2018) and Zoo attack (Chen et al., 2017) | attack successful rate, number of queries
| 2021 | Poisoning Attacks against Knowledge Graph-based Recommendation Systems Using Deep Reinforcement Learning/Neural Computing and Applications | DQN framework for conducting poisoning attacks | Knowledge Graph-based recommendation systems | add, delete edges | MovieLens-1M data set, an industry–academia partnership fund sales agency | Knowledge Graph-based Recommender Systems	| white-box attacks (can be transferred to black-box attacks) | non-targeted (maximize the hit rate) | poison | None, Random attack, Zhang | hit rate (Target users are those who have not rated the target items in the training set. Therefore, we present the indicator as Hit@ K, where K is equal to 1, 3, 5, and 10) and precision (precision is the ratio of the accurate recommended items to all the recommended items)
| 2021 | FHA: Fast Heuristic Attack Against Graph Convolutional Networks/ICDS 2021 | Fast Heuristic Attack (FHA) algorithm, which deliberately links training nodes to nodes of different classes | GCN, R-GCN, GCN-Jaccard, GCN-SVD, Pro-GNN | add edges (deliberately links training nodes to nodes of different classes) | Cora, Citeseer, Cora-ML | Node Classification | grey-box | target (one training-specific label and one universal label, For the training-specific label, we only connect training nodes of this label. For the universal label, we connect both the training nodes of this label and non-training nodes with the same pseudo-label.) | evasion | Mettack (grey-box), PDG Attack (white-box), DICE (white-box) and Random (black-box) | precision, run-time analysis
| 2021 | Inference Attacks Against Graph Neural Networks/USENIX Security 2022 | 3 different attacks |  3-layer SAGE as node embedding model, and 3 types of graph pooling modules (namely MeanPool, DiffPool, and MinCutPool) | Property Inference Attack: Given the target graph embedding HGT , the attack goal is to infer the basic properties of GT, Subgraph Inference Attack: Given the target graph embedding HGT and a subgraph of interest GS, the attack goal is to infer whether GS is contained in G, Graph Reconstruction Attack: Given the graph embedding HGT , the attack goal is to reconstruct a graph GR that shares similar graph structural statistics  | DD, ENZYMES, AIDS, NCI1, and OVCAR-8H | Graph/Property Inference | N/A | target | N/A | See metrics | task1: baseline attack is Random Guessing (Random) and Directly Summarizing the Auxiliary Dataset (Baseline), metric is accuracy(Number of nodes, number of edges, graph density, graph diameter, and graph radius); task2: 3 embedding models, sampling method is Random Walk, Snowball and FireForest,  metric is AUC; task 3: 3 embedding models, metric is accuracy ｜
| 2021 | Graph-Fraudster: Adversarial Attacks on Graph Neural Network Based Vertical Federated Learning/ Arxiv | Graph-Fraudster | GVFL: GCN; SGC; RGCN | adding noise to global node embedding;<br>add/delete edges | Poisoning | targeted | White(?) |  Cora; Cora ML; Citeseer; Pol.Blogs; Pubmed | Node Classification, Federated Learning |

## Graph Metrics -- measuring the difference between clean graph and attacked graph

| Name| Type| Math Formulation |Ref.|Note|
| ------ | ------ | ------ | ------ | ------ |
| - | -|- | - |-|-| -|


